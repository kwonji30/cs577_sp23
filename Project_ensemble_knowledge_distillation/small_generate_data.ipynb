{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b53abd9a-bc93-44c2-a474-56e030243763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## from torch.utils.data import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import warnings\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d09f2dc-3e08-4995-9aed-b3f3c0742fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_sequences(sequences):\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if seq.size(0) <= 65:\n",
    "            padded_seq = torch.nn.functional.pad(seq, (0, 0, 0, 65 - seq.size(0)), mode='constant', value=0)\n",
    "        else:\n",
    "            padded_seq = seq[:65]\n",
    "        padded_sequences.append(padded_seq)\n",
    "    return torch.stack(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "157256e3-10dd-4ef2-a57f-12b2e7c27251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe2f1d4-02e1-4dd2-b192-75d3ca2253de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "class WiCDataset(Dataset):\n",
    "    def __init__(self, path, mode):\n",
    "        self.mode = mode\n",
    "        if mode == \"gpt\":\n",
    "            self.mode = 'gpt2'\n",
    "            self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "            self.model = GPT2Model.from_pretrained('gpt2').to(device)\n",
    "        elif mode == \"bert\":\n",
    "            self.mode = 'bert-base-uncased'\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.mode) \n",
    "            self.model = AutoModel.from_pretrained(self.mode).to(device)\n",
    "\n",
    "        df_data = pd.read_csv(path+\"data.txt\",\n",
    "                              delimiter='\\t',\n",
    "                              names=['Target Word', 'PoS', 'Index', 'Context1', 'Context2'])\n",
    "        df_label = pd.read_csv(path+'gold.txt',\n",
    "                               delimiter='\\t',\n",
    "                               names=['label'])\n",
    "        self.data = pd.concat([df_data, df_label], axis=1)\n",
    "        self.data['Joined'] = self.data['Context1'] + \" \" + self.data['Context2']\n",
    "        self.data['label'] = self.data['label'].map(lambda x: 0 if x == 'F' else 1)\n",
    "        #self.maxLength = find_maxLength(self.data['Joined'].tolist(), self.tokenizer)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'gpt2':\n",
    "            gpt_token = self.tokenizer(self.data['Joined'].iloc[idx], return_tensors='pt').to(device)\n",
    "            gpt_outputs = self.model(gpt_token['input_ids'])[0]\n",
    "            padded_outputs = pad_sequences(gpt_outputs)\n",
    "            return (padded_outputs, torch.tensor(self.data.iloc[idx]['label'], dtype=torch.float32)) \n",
    "            \n",
    "        \n",
    "        elif self.mode == 'bert-base-uncased':\n",
    "            bert_token = self.tokenizer(self.data['Joined'].iloc[idx], padding='max_length', return_tensors='pt', max_length=68).to(device)        \n",
    "            with torch.inference_mode():\n",
    "                bert_outputs = self.model(**bert_token)\n",
    "            return (bert_outputs[0], torch.tensor(self.data.iloc[idx]['label'], dtype=torch.float32))\n",
    "        \n",
    "        \n",
    "train_path = r\"C:\\Users\\joowa\\OneDrive\\Spring 2023\\CS577\\Project\\WiC_dataset\\train\\train.\"\n",
    "valid_path = r\"C:\\Users\\joowa\\OneDrive\\Spring 2023\\CS577\\Project\\WiC_dataset\\dev\\dev.\"\n",
    "test_path = r\"C:\\Users\\joowa\\OneDrive\\Spring 2023\\CS577\\Project\\WiC_dataset\\test\\test.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfdf4eea-b5fa-479c-94a1-e92e312985f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_data = WiCDataset(train_path, \"bert\")\n",
    "bert_dataloader = torch.utils.data.DataLoader(bert_data,\n",
    "                                             batch_size=32,\n",
    "                                             shuffle=False,\n",
    "                                             drop_last=False)\n",
    "gpt_data = WiCDataset(train_path, \"gpt\")\n",
    "gpt_dataloader = torch.utils.data.DataLoader(gpt_data,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle = False,\n",
    "                                            drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "887f6fea-ba1c-4c30-b026-d23ac6ef1954",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = DNN(input_size = 52224, hidden_size=64, num_classes=1).to(device)\n",
    "bert_model.load_state_dict(torch.load(\"bert_model_wic_small.pth\"))\n",
    "gpt_model = DNN(input_size = 49920, hidden_size=64, num_classes=1).to(device)\n",
    "gpt_model.load_state_dict(torch.load(\"gpt_model_wic_small_1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc7f925-e9ab-4e26-a513-9d0395e0b8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(dataloader, model, mode, device):\n",
    "    result = []\n",
    "    if mode == \"glove\":\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for inputs, _, seq_lengths in dataloader:\n",
    "                inputs, seq_lengths = inputs.to(device), seq_lengths.to(device)\n",
    "                test_logits = model(inputs, seq_lengths)\n",
    "                result.append(torch.sigmoid(test_logits))\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for inputs, _ in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                flattened_inputs = inputs.view(inputs.size(0), -1)\n",
    "                test_logits = model(flattened_inputs)\n",
    "                result.append(torch.sigmoid(test_logits))\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec3e2734-089c-4f1c-a8ca-ab60b57b241a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt_output = predict(gpt_dataloader, gpt_model, \"gpt\", device)\n",
    "bert_output = predict(bert_dataloader, bert_model, \"bert\", device)\n",
    "gpt_vector = torch.cat(gpt_output, dim=0).squeeze()\n",
    "bert_vector = torch.cat(bert_output, dim=0).squeeze()\n",
    "average_vector = torch.mean(torch.stack([gpt_vector, bert_vector]), dim=0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfb3b0b9-3c6a-4603-8f00-aafc93ec2355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path+'data.txt',\n",
    "                delimiter='\\t',\n",
    "                names=['Target Word', 'PoS', 'Index', 'Context1', 'Context2'])\n",
    "df['Joined'] = df['Context1'] + \" \" + df['Context2']\n",
    "df = df.assign(Label=average_vector)\n",
    "df = df.drop(['PoS', 'Index', 'Context1', 'Context2'], axis=1)\n",
    "df.to_csv('small_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "316744f2-1072-4581-afd7-d252386d679b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Word</th>\n",
       "      <th>Joined</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carry</td>\n",
       "      <td>You must carry your camping gear . Sound carri...</td>\n",
       "      <td>3.909200e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>Messages must go through diplomatic channels ....</td>\n",
       "      <td>3.783608e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>break</td>\n",
       "      <td>Break an alibi . The wholesaler broke the cont...</td>\n",
       "      <td>1.034690e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cup</td>\n",
       "      <td>He wore a jock strap with a metal cup . Bees f...</td>\n",
       "      <td>8.908972e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy</td>\n",
       "      <td>The Academy of Music . The French Academy .</td>\n",
       "      <td>1.423036e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>krona</td>\n",
       "      <td>Piecas kronas — five krona . Kronas kurss — th...</td>\n",
       "      <td>8.909018e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>conflict</td>\n",
       "      <td>The harder the conflict the more glorious the ...</td>\n",
       "      <td>4.503391e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>answer</td>\n",
       "      <td>Answer the riddle . Answer a question .</td>\n",
       "      <td>7.800645e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>play</td>\n",
       "      <td>Play the casinos in Trouville . Play the races .</td>\n",
       "      <td>7.776666e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>invasion</td>\n",
       "      <td>An invasion of bees . An invasion of mobile ph...</td>\n",
       "      <td>5.088116e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5428 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target Word                                             Joined   \n",
       "0          carry  You must carry your camping gear . Sound carri...  \\\n",
       "1             go  Messages must go through diplomatic channels ....   \n",
       "2          break  Break an alibi . The wholesaler broke the cont...   \n",
       "3            cup  He wore a jock strap with a metal cup . Bees f...   \n",
       "4        academy        The Academy of Music . The French Academy .   \n",
       "...          ...                                                ...   \n",
       "5423       krona  Piecas kronas — five krona . Kronas kurss — th...   \n",
       "5424    conflict  The harder the conflict the more glorious the ...   \n",
       "5425      answer            Answer the riddle . Answer a question .   \n",
       "5426        play   Play the casinos in Trouville . Play the races .   \n",
       "5427    invasion  An invasion of bees . An invasion of mobile ph...   \n",
       "\n",
       "             Label  \n",
       "0     3.909200e-01  \n",
       "1     3.783608e-08  \n",
       "2     1.034690e-08  \n",
       "3     8.908972e-01  \n",
       "4     1.423036e-03  \n",
       "...            ...  \n",
       "5423  8.909018e-01  \n",
       "5424  4.503391e-01  \n",
       "5425  7.800645e-01  \n",
       "5426  7.776666e-02  \n",
       "5427  5.088116e-01  \n",
       "\n",
       "[5428 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49724278-de10-4cdb-aa0a-6cc29ae9ed38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
